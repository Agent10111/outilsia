import { NextApiRequest, NextApiResponse } from 'next';
import OpenAI from 'openai';

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENAI_PROJECT_ID = process.env.OPENAI_PROJECT_ID;

if (!OPENAI_API_KEY) {
    throw new Error('La cl√© API OpenAI n\'est pas configur√©e. Veuillez d√©finir la variable d\'environnement OPENAI_API_KEY.');
}

if (!OPENAI_PROJECT_ID) {
    throw new Error('L\'ID de projet OpenAI n\'est pas configur√©. Veuillez d√©finir la variable d\'environnement OPENAI_PROJECT_ID.');
}

const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
  project: OPENAI_PROJECT_ID // üî• obligatoire avec sk-proj
});

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'M√©thode non autoris√©e' });
    }

    const { messages } = req.body;

    console.log('üîç Corps de la requ√™te re√ßu :', req.body);

    if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({ error: 'Requ√™te invalide : le champ "messages" est requis et doit √™tre un tableau.' });
    }

    try {
        console.log("üì§ Envoi √† OpenAI :", {
            model: 'gpt-4',
            messages
        });

        const completion = await openai.chat.completions.create({
            model: 'gpt-4',
            messages,
            temperature: 0.3,
            max_tokens: 800,
        });

        const reply = completion.choices[0].message.content;

        console.log("‚úÖ R√©ponse OpenAI :", reply);

        console.log("üß† Contenu renvoy√© au frontend :", reply);

        return res.status(200).json({ message: reply });
    } catch (error) {
        console.error('‚ùå Erreur lors de la communication avec OpenAI :', error);
        console.error('‚ùå Erreur de requ√™te :', error);
        return res.status(500).json({ error: 'Erreur interne du serveur' });
    }
}